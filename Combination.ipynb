{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e21549",
   "metadata": {},
   "source": [
    "# Propagation of correlations in MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c9286",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8738b510",
   "metadata": {},
   "source": [
    "It was pointed out that the integration can not be separated for correlated parameters. Below we briefly summarize the idea. From Bayes' theorem, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb0dfc4",
   "metadata": {},
   "source": [
    "$$\\pi(m_{\\nu}, \\vec{\\alpha}, \\theta_{1}, \\theta_{2} | y_1, y_2) \\propto \\pi(y_1, y_2 | m_{\\nu}, \\vec{\\alpha}, \\theta_{1}, \\theta_{2}) \\cdot \\pi(m_{\\nu}, \\vec{\\alpha}, \\theta_{1}, \\theta_{2}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2088912c",
   "metadata": {},
   "source": [
    "Here, $\\pi$ is the probability distribution, $m_\\nu$ is the parameter of interest, $\\vec{\\alpha}$ are the shared or independent parameters, $y_1$ and $y_2$ are the two separated measurements, each with a nuisance parameter $\\theta_1$ and $\\theta_{2}$. These two nuisance parameters are partly correlated, with a correlation coefficient $\\rho$, mean values $\\mu_1, \\mu_2$ and standard errors $\\sigma_1, \\sigma_2$ separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf75a2a",
   "metadata": {},
   "source": [
    "Ideally, to obtain information for marginal posterior distribution of $m_\\nu$, a multi-dimensional integration over $\\vec{\\alpha}, \\theta_1$ and $\\theta_2$ is required. If, however, $\\theta_{1}$ and $\\theta_{2}$ have partial correlation, the integration over $\\theta_1$ and $\\theta_2$ is not separable. In a Markov Chain sampling, this indicates that a separated sampling in sequence might not be possible for partly correlated parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72326e4",
   "metadata": {},
   "source": [
    "## An analytical solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacd54f5",
   "metadata": {},
   "source": [
    "Under a specific case of multivariate normal distribution for both priors and posteriors, the integration might be calculated analytically regardless of the correlations. Usually, to avoid multiple usage of the same data set, the calibration runs determining $\\theta_1$ and $\\theta_2$ are separated from the main measurements. That is to say, the prior on $\\theta_1$ and $\\theta_2$ are usually uncorrelated with the other parameters. Therefore,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f212b2a3",
   "metadata": {},
   "source": [
    "$$\\pi(m_{\\nu}, \\vec{\\alpha}, \\theta_{1}, \\theta_{2}) = \\pi(m_{\\nu})\\cdot\\pi(\\vec{\\alpha})\\cdot\\pi(\\theta_1, \\theta_2),$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81859cc",
   "metadata": {},
   "source": [
    "where \n",
    "$$\\pi(\\theta_1, \\theta_2) \\sim \\pi (\\mu_1, \\mu_2; \\sigma_1, \\sigma_2, \\rho_{12})$$ are the calibration results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05aeae6",
   "metadata": {},
   "source": [
    "Rewrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf92e51",
   "metadata": {},
   "source": [
    "$$\\pi(\\theta_1, \\theta_2) = \\pi(\\theta_1) \\cdot \\pi(\\theta_2 | \\theta_1),$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceefa81",
   "metadata": {},
   "source": [
    "and also note that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12698833",
   "metadata": {},
   "source": [
    "$$\\pi(y_1, y_2 | m_{\\nu}, \\vec{\\alpha}, \\theta_{1}, \\theta_{2}) = \\pi(y_1 | m_{\\nu}, \\vec{\\alpha}, \\theta_{1}) \\cdot \\pi(y_2 | m_{\\nu}, \\vec{\\alpha}, \\theta_{2}),$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d15cd4c",
   "metadata": {},
   "source": [
    "we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfb2b89",
   "metadata": {},
   "source": [
    "$$\\pi(m_{\\nu}, \\vec{\\alpha}, \\theta_{1}, \\theta_{2} | y_1, y_2) \\propto \\pi(m_{\\nu}, \\vec{\\alpha}, \\theta_{1} | y_1) \\cdot \\pi(\\theta_2 | \\theta_1) \\cdot \\pi(y_2 | m_{\\nu}, \\vec{\\alpha}, \\theta_{2}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358a8b4",
   "metadata": {},
   "source": [
    "Here we used the fact that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469d725",
   "metadata": {},
   "source": [
    "$$\\pi(m_{\\nu}, \\vec{\\alpha}, \\theta_{1} | y_1) \\propto \\pi(y_1 | m_{\\nu}, \\vec{\\alpha}, \\theta_{1}) \\cdot \\pi(m_{\\nu}) \\cdot \\pi(\\vec{\\alpha}) \\cdot \\pi(\\theta_1).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2298477e",
   "metadata": {},
   "source": [
    "From this expression, the joint probability distribution of all parameters can be derived by sampling the second measurement with prior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1047949",
   "metadata": {},
   "source": [
    "$$\\pi(m_{\\nu}, \\vec{\\alpha}, \\theta_{1} | y_1) \\cdot \\pi(\\theta_2 | \\theta_1)$$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc88ed9",
   "metadata": {},
   "source": [
    "Now we want to get rid of $\\theta_1$ from the sampling of second measurement, since it only affects prior and has no impact on the likelihood function. That means we want to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f357759",
   "metadata": {},
   "source": [
    "$$P = \\int_{\\theta_1} \\pi(m_{\\nu}, \\vec{\\alpha}, \\theta_{1} | y_1) \\cdot \\pi(\\theta_2 | \\theta_1) d\\theta_1.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c391e4c4",
   "metadata": {},
   "source": [
    "From the sampling of first measurement, we obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632baaae",
   "metadata": {},
   "source": [
    "$$\\pi(m_{\\nu}, \\vec{\\alpha}, \\theta_{1} | y_1) \\sim \\textit{N}(\\vec{M}, \\Sigma).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25c17ba",
   "metadata": {},
   "source": [
    "The conditional distribution based on a multivariate normal distribution can be expressed as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f52bec1",
   "metadata": {},
   "source": [
    "$$\\pi(\\theta_2 | \\theta_1) \\sim \\textit{N}\\left( \\mu_2 + (\\theta_1-\\mu_1)\\cdot \\rho_{12} \\frac{\\sigma_2}{\\sigma_1}, \\sigma_2\\sqrt{1 - \\rho_{12}^2}\\right),$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaf5526",
   "metadata": {},
   "source": [
    "Since $P$ is given by a convolution of two (multi)variate normal distributions, $P$ itself also follows a normal distribution $N(\\vec{M^{'}}, \\Sigma^{'})$. In the following we will evaluate $\\vec{M^{'}}$ and $\\Sigma^{'}$ in explicit forms, but not in a mathematically rigorous approach. Any complementary work to provide a proof / precise computation would be greatly appreciated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c77cc8",
   "metadata": {},
   "source": [
    "### Mean and sigma values of the $\\theta_2$ prior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ed3fdd",
   "metadata": {},
   "source": [
    "It is obvious that the new normal distribution has the same mean and sigma values for parameters $m_\\nu$ and $\\vec{\\alpha}$, but has a different mean and sigma for $\\theta_2$. Without a solid proof, since $\\theta_2$ only has its dependency on $\\theta_1$ from calibration, its explicit prior should be independent of the measured $m_\\nu$ and $\\vec{\\alpha}$, and their correlations with $\\theta_1$. This can be understood as taking $\\theta_2$ as the parameter of interest, and the integration over $m_\\nu$ and $\\vec{\\alpha}$ should have no impact on the $\\theta_2$ distribution. Therefore, its form only depends on the calibration measurements and main measurements of $\\theta_1$,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427d163c",
   "metadata": {},
   "source": [
    "$$ P \\sim \\int_{\\theta_1} \\exp\\left\\{-\\frac{1}{2}\\cdot\\left[\\frac{(\\theta_1-\\hat{\\theta_1})^2}{\\hat{\\sigma_1}^2}+\\frac{(\\theta_2-\\mu_2-(\\theta_1-\\mu_1)\\cdot \\rho_{12} \\frac{\\sigma_2}{\\sigma_1})^2}{\\sigma_2^2(1-\\rho_{12}^2)}\\right]\\right\\}d\\theta_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1d59f1",
   "metadata": {},
   "source": [
    "Note that $M_1 = \\hat{\\theta_1}$ is the estimated mean value from main measurement, while $\\mu_1$ is the estimated mean value for the same parameter but from calibration measurement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3d47ab",
   "metadata": {},
   "source": [
    "The expression above is a standard exponential integration, and is evaluated to be (up to a normalization constant):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba265d7f",
   "metadata": {},
   "source": [
    "$$P \\sim \\exp\\, \\left\\{ -\\frac{1}{2\\left[ \\hat{\\sigma_1}^2\\rho_{12}^2\\frac{\\sigma_2^2}{\\sigma_1^2} + \\sigma_2^2(1-\\rho_{12}^2) \\right]} \\left[\\theta_2 - \\mu_2 + (\\mu_1-\\hat{\\theta_1})\\rho_{12}\\frac{\\sigma_2}{\\sigma_1} \\right]^2\\right\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b666944",
   "metadata": {},
   "source": [
    "Therefore we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18477ceb",
   "metadata": {},
   "source": [
    "$$\\sigma_2^{'2} = \\hat{\\sigma_1}^2\\rho_{12}^2\\frac{\\sigma_2^2}{\\sigma_1^2} + \\sigma_2^2(1-\\rho_{12}^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afac1fb",
   "metadata": {},
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f2f30d",
   "metadata": {},
   "source": [
    "$$\\mu_2^{'} = \\mu_2 - (\\mu_1 - \\hat{\\theta_1})\\rho_{12}\\frac{\\sigma_2}{\\sigma_1}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239957f9",
   "metadata": {},
   "source": [
    "### Correlation coefficient of $\\theta_2$ and $m_\\nu$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737bbf74",
   "metadata": {},
   "source": [
    "It is expected that the correlation of $\\theta_2$ and $m_\\nu$ (or any of $\\alpha$'s) does not depend on any other parameter, except for $\\theta_1$. Therefore for simplicity we only work in the 3-parameter case ($\\theta_2$, $m_\\nu$ and $\\theta_1$), and the formula is expected to also hold for the general case. (Proof might be required!) The multivariate normal distribution from first measurement, $\\textit{N}(\\vec{M}, \\Sigma)$, reduces to a bivariate form,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398defab",
   "metadata": {},
   "source": [
    "$$\\textit{N}(\\vec{M}, \\Sigma) \\sim \\exp \\left[ -\\frac{1}{2(1-\\rho_{m1}^2)}\\cdot \\left( \\frac{m_\\nu^2}{\\hat{\\sigma_m}^2} - 2\\rho_{m1} \\frac{\\theta_1m_\\nu}{\\hat{\\sigma_m}\\hat{\\sigma_1}} + \\frac{\\theta_1^2}{\\hat{\\sigma_1}^2}\\right)\\right].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745d6fd8",
   "metadata": {},
   "source": [
    "With this, the integration becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff715058",
   "metadata": {},
   "source": [
    "$$P \\sim \\int \\exp\\left[ -\\frac{1}{2(1-\\rho_{m1}^2)}\\cdot \\left( \\frac{m_\\nu^2}{\\hat{\\sigma_m}^2} - 2\\rho_{m1} \\frac{\\theta_1m_\\nu}{\\hat{\\sigma_m}\\hat{\\sigma_1}} + \\frac{\\theta_1^2}{\\hat{\\sigma_1}^2}\\right)\\right] \\exp \\left\\{ -\\frac{\\left[\\theta_2 - \\mu_2 - (\\theta_1-\\mu_1)\\rho_{12} \\frac{\\sigma_2}{\\sigma_1}\\right]^2}{2\\sigma_2^2(1-\\rho_{12}^2)}\\right\\}d\\theta_1.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a6731",
   "metadata": {},
   "source": [
    "This expression seems horrible. But we already know that, the correlation coefficient does not scale with the variance and the mean value of the measurement. Therefore, we can simplify the expression (only for the purpose of obtaining correlation) by assuming $\\hat{\\sigma_m}=\\hat{\\sigma_1}=\\sigma_1=\\sigma_2=1$, $\\mu_1=\\mu_2=0.$ Now the integration yields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f64d3d",
   "metadata": {},
   "source": [
    "$$P \\sim \\exp \\,\\left\\{ -\\frac{m_\\nu^2}{2(1-\\rho_{m1}^2)}-\\frac{\\theta_2^2}{2(1-\\rho_{12}^2)} + \\frac{\\left(\\frac{\\rho_{m1}m_\\nu}{1-\\rho_{m1}^2} + \\frac{\\rho_{12}\\theta_2}{1-\\rho_{12}^2}\\right)^2}{4\\left[\\frac{1}{2(1-\\rho_{m1}^2)}+\\frac{\\rho_{12}^2}{2(1-\\rho_{12}^2)}\\right]} \\right\\}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf80549",
   "metadata": {},
   "source": [
    "This should be equivalent to a bivariate normal distribution in between $m_\\nu$ and $\\theta_2$ with correlation coefficient $\\rho_{m2}$. Therefore,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fc3597",
   "metadata": {},
   "source": [
    "$$-\\frac{1}{2(1-\\rho_{m2}^2)} = -\\frac{1}{2(1-\\rho_{m1}^2)} + \\left.\\left( \\frac{\\rho_{m1}}{1-\\rho_{m1}^2}\\right)^2 \\middle/ 2\\left( \\frac{1}{1-\\rho_{m1}^2} + \\frac{\\rho_{12}^2}{1-\\rho_{12}^2} \\right) \\right. .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da3b53d",
   "metadata": {},
   "source": [
    "Simplifying this we get"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7d0859",
   "metadata": {},
   "source": [
    "$$\\rho_{m2}^2 = \\rho_{12}^2 \\rho_{m1}^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e49ac9",
   "metadata": {},
   "source": [
    "With this we almost obtained an expression for $\\rho_{m2}$, except for its sign. This can be derived by a very simple example: if $\\theta_1$ and $\\theta_2$ are fully correlated, we know that $\\rho_{m2} = \\rho_{m1}$. Therefore the sign is chosen such that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee766a60",
   "metadata": {},
   "source": [
    "$$\\rho_{m2} = \\rho_{m1} \\cdot \\rho_{12}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5223e8",
   "metadata": {},
   "source": [
    "# A toy MC study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0b20b8",
   "metadata": {},
   "source": [
    "Here we perform a toy Monte Carlo study to prove that performing a sequential sampling with the method above yields an equivalent result with combined sampling. Emcee is used as the sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8739135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated measurement 1 has mean value: \n",
      "[4.49577033 8.36220707 1.40351164]\n",
      "\n",
      "and covariance matrix: \n",
      "[[ 8.61991175 -5.08030304  1.34832765]\n",
      " [-5.08030304  9.92945783  1.51063718]\n",
      " [ 1.34832765  1.51063718  7.37973086]]\n",
      "\n",
      "Generated measurement 2 has mean value: \n",
      "[9.1091299  5.1019116  4.43913297]\n",
      "\n",
      "and covariance matrix: \n",
      "[[ 5.11079882 -2.17417691 -0.55227383]\n",
      " [-2.17417691  3.06725646 -0.81344982]\n",
      " [-0.55227383 -0.81344982  3.57666577]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# We perform the test in 4 dimensions (a, b, c, d), where (a, b) \n",
    "# are shared parameters for two separate measurements, c is a nuisance\n",
    "# parameter affecting measurement 1, d is the same parameter (not \n",
    "# necessarily having the same value) affecting measurement 2.\n",
    "# There is another calibration measurement on (c, d).\n",
    "\n",
    "# Generate a \"true\" correlation for (a, b, c, d).\n",
    "from scipy.stats import random_correlation\n",
    "ndim = 4\n",
    "eigs_rnd = np.random.rand(ndim)\n",
    "corr = random_correlation.rvs(eigs=eigs_rnd / np.sum(eigs_rnd) * ndim)\n",
    "#print(\"Generated correlation matrix: \\n\", corr, \"\\n\", sep=\"\")\n",
    "\n",
    "# Generate a \"true\" mean value for (a, b, c, d).\n",
    "mean = np.random.rand(ndim)*10\n",
    "#print(\"Generated mean values: \\n\", mean, \"\\n\", sep=\"\")\n",
    "\n",
    "# Generate measurement 1, 2 and calibration. To make it realistic,\n",
    "# measurements have less sensitivity on (c, d) compared with calibration.\n",
    "\n",
    "uncertainty_1 = np.random.normal(3, 0.3, ndim-1) # measurements on (a, b, c)\n",
    "uncertainty_2 = np.random.normal(2, 0.2, ndim-1) # measurements on (a, b, d)\n",
    "uncertainty_c = np.random.normal(1, 0.1, 2) # measurement on (c, d)\n",
    "\n",
    "\n",
    "# To make it clear, we separate each campaign.\n",
    "# Measurement 1\n",
    "dim_1 = [0, 1, 2]\n",
    "corr_1 = np.zeros((len(dim_1), len(dim_1)))\n",
    "for i, index_i in enumerate(dim_1):\n",
    "    for j, index_j in enumerate(dim_1):\n",
    "        corr_1[i][j] = corr[index_i][index_j]\n",
    "        \n",
    "cov_1 = np.array([np.multiply(corr_row, uncertainty_1)*uncertainty_1[index] for index, corr_row in enumerate(corr_1)])\n",
    "mean_1 = np.random.multivariate_normal(mean=[mean[i] for i in dim_1], cov=cov_1, size=1)[0]\n",
    "\n",
    "print(\"Generated measurement 1 has mean value: \\n\", mean_1, \"\\n\\nand covariance matrix: \\n\", cov_1, \"\\n\", sep=\"\")\n",
    "\n",
    "# Measurement 2\n",
    "dim_2 = [0, 1, 3]\n",
    "corr_2 = np.zeros((len(dim_1), len(dim_1)))\n",
    "for i, index_i in enumerate(dim_2):\n",
    "    for j, index_j in enumerate(dim_2):\n",
    "        corr_2[i][j] = corr[index_i][index_j]\n",
    "        \n",
    "cov_2 = np.array([np.multiply(corr_row, uncertainty_2)*uncertainty_2[index] for index, corr_row in enumerate(corr_2)])\n",
    "mean_2 = np.random.multivariate_normal(mean=[mean[i] for i in dim_2], cov=cov_2, size=1)[0]\n",
    "\n",
    "print(\"Generated measurement 2 has mean value: \\n\", mean_2, \"\\n\\nand covariance matrix: \\n\", cov_2, \"\\n\", sep=\"\")\n",
    "\n",
    "# Calibration\n",
    "dim_c = [2, 3]\n",
    "corr_c = np.zeros((len(dim_c), len(dim_c)))\n",
    "for i, index_i in enumerate(dim_c):\n",
    "    for j, index_j in enumerate(dim_c):\n",
    "        corr_c[i][j] = corr[index_i][index_j]\n",
    "\n",
    "cov_c = np.array([np.multiply(corr_row, uncertainty_c)*uncertainty_c[index] for index, corr_row in enumerate(corr_c)])\n",
    "mean_c = np.random.multivariate_normal(mean=[mean[i] for i in dim_c], cov=cov_c, size=1)[0]\n",
    "\n",
    "#print(\"Generated calibration has mean value: \\n\", mean_c, \"\\n\\nand covariance matrix: \\n\", cov_c, \"\\n\", sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5845ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now starting combined sampling.\n",
      "Sampled mean values for (a, b): (7.319333998344855, 5.721772767737799) \n",
      "and sigma values for (a, b): (3.0868002325249773, 2.190737669806267)\n"
     ]
    }
   ],
   "source": [
    "# Now we use MCMC to produce the posterior distribution in different approaches.\n",
    "def multivar_likelihood(x, mu, cov):\n",
    "    diff = x - mu\n",
    "    return -0.5 * np.dot(diff, np.linalg.solve(cov, diff))\n",
    "\n",
    "# First attempt, combined sampling.\n",
    "print(\"Now starting combined sampling.\")\n",
    "nwalkers = 2 * ndim\n",
    "p0 = np.random.randn(nwalkers, ndim)\n",
    "def combined_likelihood(x):\n",
    "    return (multivar_likelihood(np.array([x[i] for i in dim_1]), mean_1, cov_1) +\n",
    "            multivar_likelihood(np.array([x[i] for i in dim_2]), mean_2, cov_2) +\n",
    "            multivar_likelihood(np.array([x[i] for i in dim_c]), mean_c, cov_c))\n",
    "\n",
    "import emcee\n",
    "nSamples = 100000\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, combined_likelihood)\n",
    "sampler.run_mcmc(p0, nSamples, progress=False)\n",
    "\n",
    "samples = sampler.get_chain(flat=True, discard=int(nSamples/2))\n",
    "print(\"Sampled mean values for (a, b): ({0}, {1}) \\nand sigma values for (a, b): ({2}, {3})\".format(\n",
    "     np.mean(samples[:,0]), np.mean(samples[:,1]), np.var(samples[:,0]), np.var(samples[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88926030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now starting sequential sampling.\n",
      "Sampled mean values for (a, b): (7.293393766477657, 5.740462414549517) \n",
      "and sigma values for (a, b): (3.1614457404845777, 2.2283478862546127)\n"
     ]
    }
   ],
   "source": [
    "# Second attempt, sequential sampling.\n",
    "print(\"Now starting sequential sampling.\")\n",
    "from math import sqrt\n",
    "\n",
    "# First measurement\n",
    "def first_likelihood(x):\n",
    "    return multivar_likelihood(x, mean_1, cov_1)\n",
    "\n",
    "p0 = np.random.randn(nwalkers, len(mean_1))\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim-1, first_likelihood)\n",
    "sampler.run_mcmc(p0, nSamples, progress=False)\n",
    "\n",
    "samples = sampler.get_chain(flat=True, discard=int(nSamples/2))\n",
    "mean_posterior = np.mean(samples, axis=0)\n",
    "#print(\"Mean values from sampling the first measurement: \\n\", mean_posterior, \"\\n\", sep=\"\")\n",
    "\n",
    "cov_posterior = np.cov(np.swapaxes(samples, 0, 1))\n",
    "#print(\"Covariance matrix from sampling the first measurement: \\n\", cov_posterior, \"\\n\", sep=\"\")\n",
    "\n",
    "# Corrected for calibration to form a prior for the second measurement\n",
    "corr_posterior = np.corrcoef(np.swapaxes(samples, 0, 1))\n",
    "#print(\"Correlation matrix from sampling the first measurement: \\n\", corr_posterior, \"\\n\", sep=\"\")\n",
    "\n",
    "std_posterior = np.array([np.std(samples[:, par]) for par in range(len(mean_1))])\n",
    "#print(\"Posterior standard deviation: \", std_posterior, sep=\"\")\n",
    "\n",
    "cov_prior = np.zeros(cov_2.shape) # need a mapping from (a, b, c) to (a, b, d)\n",
    "\n",
    "# We could, of course, write down a fancy mapping function to handle the \n",
    "# parameters to be integrated out, but here we simply manually set the values.\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        cov_prior[i][j] = cov_posterior[i][j] # unaltered part\n",
    "\n",
    "std_2 = sqrt(std_posterior[2]**2 * corr_c[0][1]**2 * cov_c[1][1] / cov_c[0][0]\n",
    "            + cov_c[1][1] * (1-corr_c[0][1]**2)) # \\sigma_2^\\prime\n",
    "\n",
    "for i in range(2):\n",
    "    rho = corr_posterior[i][2] * corr_c[0][1]\n",
    "    cov_prior[i][2] = rho * std_2 * std_posterior[i]\n",
    "    cov_prior[2][i] = rho * std_2 * std_posterior[i]\n",
    "\n",
    "cov_prior[2][2] = std_2**2\n",
    "#print(\"Mapped covariance matrix with calibration:\\n\", cov_prior, sep=\"\")\n",
    "\n",
    "# The mean value of d as prior\n",
    "mean_prior = np.array([iValue for iValue in mean_posterior]) # a deep copy\n",
    "mean_prior[2] = mean_c[1] - (mean_c[0] - mean_posterior[2]) * corr_c[0][1] * sqrt(cov_c[1][1] / cov_c[0][0]) # \\mu_2^\\prime\n",
    "\n",
    "# Sampling the second measurement with a proper prior\n",
    "def second_likelihood(x):\n",
    "    return (multivar_likelihood(x, mean_prior, cov_prior) + # prior\n",
    "            multivar_likelihood(x, mean_2, cov_2))\n",
    "\n",
    "p0 = np.random.randn(nwalkers, len(mean_2))\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim-1, second_likelihood)\n",
    "sampler.run_mcmc(p0, nSamples, progress=False)\n",
    "samples = sampler.get_chain(flat=True, discard=int(nSamples/2))\n",
    "print(\"Sampled mean values for (a, b): ({0}, {1}) \\nand sigma values for (a, b): ({2}, {3})\".format(\n",
    "     np.mean(samples[:,0]), np.mean(samples[:,1]), np.var(samples[:,0]), np.var(samples[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d365b81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
